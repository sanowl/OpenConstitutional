{
  "model": {
    "model_name": "microsoft/DialoGPT-medium",
    "max_length": 512,
    "temperature": 0.7,
    "top_p": 0.9,
    "do_sample": true,
    "pad_token_id": 50256,
    "eos_token_id": 50256,
    "device": "cuda",
    "dtype": "float16"
  },
  "training": {
    "batch_size": 4,
    "gradient_accumulation_steps": 8,
    "learning_rate": 5e-5,
    "num_epochs": 3,
    "max_steps": -1,
    "warmup_steps": 100,
    "weight_decay": 0.01,
    "adam_epsilon": 1e-8,
    "max_grad_norm": 1.0,
    "save_steps": 500,
    "eval_steps": 100,
    "logging_steps": 10,
    "seed": 42,
    "fp16": true,
    "deepspeed_config": null,
    "use_peft": false,
    "lora_r": 8,
    "lora_alpha": 32,
    "lora_dropout": 0.1
  },
  "ppo": {
    "batch_size": 4,
    "mini_batch_size": 1,
    "ppo_epochs": 4,
    "learning_rate": 1.4e-5,
    "init_kl_coef": 0.2,
    "target_kl": 6.0,
    "adap_kl_ctrl": true,
    "gamma": 1.0,
    "lam": 0.95,
    "cliprange": 0.2,
    "cliprange_value": 0.2,
    "vf_coef": 0.1,
    "max_grad_norm": 0.5,
    "forward_batch_size": 4,
    "gradient_accumulation_steps": 1
  },
  "data": {
    "dataset_name": "Anthropic/hh-rlhf",
    "dataset_subset": null,
    "train_split": "train",
    "test_split": "test",
    "max_samples": 1000,
    "max_input_length": 512,
    "max_output_length": 512,
    "shuffle": true,
    "num_workers": 4,
    "preprocessing_num_workers": 4
  },
  "evaluation": {
    "eval_batch_size": 8,
    "eval_steps": 100,
    "save_eval_results": true,
    "eval_output_dir": "eval_results",
    "metrics": ["helpfulness", "harmlessness", "honesty"],
    "human_eval": false,
    "safety_eval": true
  },
  "logging": {
    "project_name": "constitutional-ai",
    "run_name": null,
    "output_dir": "outputs",
    "logging_dir": "logs",
    "log_level": "INFO",
    "use_wandb": false,
    "wandb_project": "constitutional-ai",
    "wandb_entity": null,
    "save_model": true,
    "save_optimizer": false
  },
  "constitutional_principles": [
    "Choose the response that is more helpful, honest, and harmless.",
    "Choose the response that is more truthful and accurate.",
    "Choose the response that avoids harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.",
    "Choose the response that is more respectful and considerate of different viewpoints.",
    "Choose the response that promotes human autonomy and well-being.",
    "Choose the response that is more balanced and avoids extreme positions.",
    "Choose the response that protects privacy and doesn't encourage surveillance.",
    "Choose the response that is more transparent about its limitations and uncertainty.",
    "Choose the response that encourages critical thinking rather than blind acceptance.",
    "Choose the response that is more constructive and solution-oriented."
  ],
  "critique_model": "microsoft/DialoGPT-medium",
  "revision_model": "microsoft/DialoGPT-medium",
  "preference_model": "microsoft/DialoGPT-medium",
  "num_critique_rounds": 1,
  "num_revision_rounds": 1,
  "use_self_critique": true,
  "critique_temperature": 0.7,
  "revision_temperature": 0.7,
  "preference_temperature": 0.7
}