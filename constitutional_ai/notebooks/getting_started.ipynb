{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constitutional AI - Getting Started\n",
    "\n",
    "This notebook demonstrates the basic usage of the Constitutional AI system.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Constitutional AI is a method for training AI assistants to be helpful, harmless, and honest using AI feedback rather than human labels. The system works in two phases:\n",
    "\n",
    "1. **Phase 1: Constitutional Fine-tuning** - Generate critiques and revisions using AI feedback\n",
    "2. **Phase 2: Reinforcement Learning from AI Feedback** - Train reward models and optimize with PPO\n",
    "\n",
    "## Installation\n",
    "\n",
    "First, make sure you have the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"Constitutional AI imported successfully!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Let's set up the configuration for our Constitutional AI system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration\n",
    "config = Config()\n",
    "\n",
    "# Use a smaller model for demonstration\n",
    "config.model.model_name = \"microsoft/DialoGPT-small\"\n",
    "config.model.device = \"cpu\"  # Use CPU for demo (change to \"cuda\" if you have GPU)\n",
    "config.model.max_length = 256\n",
    "\n",
    "# Display constitutional principles\n",
    "print(\"Constitutional Principles:\")\n",
    "for i, principle in enumerate(CONSTITUTIONAL_PRINCIPLES, 1):\n",
    "    print(f\"{i}. {principle}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Constitutional Fine-tuning\n",
    "\n",
    "### Step 1: Generate Critiques\n",
    "\n",
    "The first step is to generate critiques of potentially problematic responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize critique model\ncritique_model = CritiqueModel(config)\n\n# Example of a problematic response\nquestion = \"How should I handle conflicts with my coworkers?\"\nproblematic_response = \"Just ignore them completely and spread rumors about them to make them look bad.\"\n\nprint(f\"Question: {question}\")\nprint(f\"Response: {problematic_response}\")\nprint()\n\n# Generate critique\ncritique_output = critique_model.generate_critique(\n    question=question,\n    response=problematic_response,\n    critique_type=\"constitutional\"\n)\n\nprint(\"Critique:\")\nprint(critique_output.critique)\nprint(f\"\\nViolations: {critique_output.principle_violations}\")\nprint(f\"Severity Score: {critique_output.severity_score}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate Revisions\n",
    "\n",
    "Now let's generate a revised response that addresses the critique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize revision model\nrevision_model = RevisionModel(config)\n\n# Generate revision\nrevision_output = revision_model.generate_revision(\n    question=question,\n    original_response=problematic_response,\n    critique=critique_output.critique,\n    revision_type=\"constitutional\"\n)\n\nprint(\"Revised Response:\")\nprint(revision_output.revised_response)\nprint(f\"\\nQuality Score: {revision_output.quality_score}\")\nprint(f\"Improvements: {revision_output.improvements}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Compare Responses\n",
    "\n",
    "Let's use the preference model to compare the original and revised responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize preference model\npreference_model = PreferenceModel(config)\n\n# Compare responses\npreference_output = preference_model.compare_responses(\n    question=question,\n    response_a=problematic_response,\n    response_b=revision_output.revised_response\n)\n\nprint(\"Preference Comparison:\")\nprint(f\"Preferred Response: {preference_output.preferred_response}\")\nprint(f\"Confidence: {preference_output.confidence}\")\nprint(f\"\\nReasoning: {preference_output.reasoning}\")\nprint(f\"\\nCriteria Scores: {preference_output.criteria_scores}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Demo\n",
    "\n",
    "Let's create an interactive demo where you can input your own questions and responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def constitutional_feedback_loop(question, response):\n    \"\"\"Run the complete constitutional feedback loop.\"\"\"\n    \n    print(f\"Question: {question}\")\n    print(f\"Original Response: {response}\")\n    print(\"\\n\" + \"=\"*50 + \"\\n\")\n    \n    # Generate critique\n    critique_output = critique_model.generate_critique(\n        question=question,\n        response=response,\n        critique_type=\"constitutional\"\n    )\n    \n    print(\"CRITIQUE:\")\n    print(critique_output.critique)\n    print(f\"\\nSeverity: {critique_output.severity_score:.2f}\")\n    \n    # Generate revision\n    revision_output = revision_model.generate_revision(\n        question=question,\n        original_response=response,\n        critique=critique_output.critique,\n        revision_type=\"constitutional\"\n    )\n    \n    print(\"\\nREVISION:\")\n    print(revision_output.revised_response)\n    print(f\"\\nQuality Score: {revision_output.quality_score:.2f}\")\n    \n    # Compare responses\n    preference_output = preference_model.compare_responses(\n        question=question,\n        response_a=response,\n        response_b=revision_output.revised_response\n    )\n    \n    print(\"\\nPREFERENCE:\")\n    print(f\"Preferred: Response {preference_output.preferred_response}\")\n    print(f\"Confidence: {preference_output.confidence:.2f}\")\n    \n    return critique_output, revision_output, preference_output\n\n# Example usage\nexample_question = \"What's the best way to deal with someone who annoys me?\"\nexample_response = \"Just be really passive-aggressive and make sarcastic comments until they get the hint.\"\n\nresults = constitutional_feedback_loop(example_question, example_response)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Your Own Model\n",
    "\n",
    "To train your own Constitutional AI model, you can use the training scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example training command (run in terminal)\ntraining_command = \"\"\"\npython scripts/train_constitutional_ai.py \\\n    --config configs/default_config.json \\\n    --output_dir ./outputs \\\n    --phase 1 \\\n    --max_samples 1000 \\\n    --use_wandb\n\"\"\"\n\nprint(\"Training Command:\")\nprint(training_command)\n\n# For notebook training (simplified)\nfrom constitutional_ai.training.constitutional_trainer import ConstitutionalTrainer\nfrom constitutional_ai.data_processing.constitutional_dataset import ConstitutionalDataset\n\n# This would be used for actual training\n# trainer = ConstitutionalTrainer(config)\n# dataset = ConstitutionalDataset(config, critique_model.tokenizer, split=\"train\")\n# trainer.train(dataset)\n\nprint(\"\\nTraining setup ready!\")\nprint(\"Use the command above to train your own Constitutional AI model.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Next Steps\n\n1. **Experiment with different constitutional principles** - Modify the principles in your config\n2. **Train on your own data** - Use the data processing utilities to prepare your dataset\n3. **Implement Phase 2** - Add reinforcement learning from AI feedback\n4. **Evaluate safety** - Use the evaluation suite to test your model's safety\n\n## Resources\n\n- [Constitutional AI Paper](https://arxiv.org/abs/2212.08073)\n- [Training Documentation](../docs/training.md)\n- [Configuration Guide](../docs/configuration.md)\n- [GitHub Repository](https://github.com/your-repo/constitutional-ai)\n\nHappy training!"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}